---
layout: cv
title: MINYU Gao's CV
pdf: true
---
# __高旻昱__

<div id="webaddress">
<i class="fi-telephone" style="margin-left:1em"></i>
<a style="margin-left:0.5em">+86-13661461891</a>
<i class="fi-mail" style="margin-left:1em"></i>
<a href="minyu.gao@outlook.com" style="margin-left:0.5em">minyu.gao@outlook.com</a>
<i class="fi-male-female" style="margin-left:1em"></i>
<a style="margin-left:0.5em">男</a><br>
<i class="fi-home" style="margin-left:1em"></i>
<a href="https://josepgao.github.io/ChatJSP/" title="chatJSP">访问我的个人chatgpt ➡️ josepgao.github.io/ChatJSP/</a>
</div>



## 教育经历

### __瑞士联邦理工（洛桑）EPFL__ `2013.9 - 2016.4`
```
瑞士，洛桑
```
- 计算机科学和生物医学工程学 Master of Science
- 深度学习，计算机图像视觉，医疗影像学，数字信号处理，机器学习
### __上海交通大学__ `2009.9 - 2013.6`
```
中国，上海
```
- 机械工程 Bachelor of Science
- 生物力学，优化理论，计算机仿真

## 主要能力概述
__计算机视觉__ 
	|目标检测 | <a href="#全景分割">全景分割</a> | <a href="#zero-shot">zero-shot</a>图像任务 | cross-domain迁移学习 |

__多模态__ 
	|图文、视频检索 Retrieval | 文本图像生成 | 通用多模态方案,如<a href="#CLIP">CLIP</a>, <a href="#ALBEF">ALBEF</a>, <a href="#BEiTV3">BEiTV3</a> |

__LLM__
	|Bert | GPT | promting engineering | scaling law |

__AI工程化__
	|数据工程 | 特征工程 | 多框架 | 边缘计算部署 | 大规模线上部署 | 模型并行化 | 模型轻量化 |

__管理经验__
	|AI算法团队及配套全栈软件团队(前后端)管理经验(4年) | 从概念到研发再到产品的全工作链流程(8年)| 与高校学术团队紧密合作经验(4年)| 

__Coding Skill__
|Python | Torch | Tensorflow | C/C++ | Linux | Docker | Kubernetes | 


## 工作经历简述

### __上海领健信息科技有限公司__ [上海] `2022.06 - now`
_算法负责人_<br>
* 负责算法团队的技术选型和核心技术研发
* 负责算法团队相关项管理

### __上海翎腾智能科技有限公司__ [上海] `2019.4 - 2022.06`
_人工智能算法负责人_<br>

* 负责深度图像识别系统内多种功能模块的设计开发
* 负责技术团队相关项目管理

### __上海第五区科技有限公司__ [上海] `2016.5 - 2019.4`
_算法专家_<br>

* 负责多项可穿戴嵌入式设备算法设计和研发

### __CSEM,瑞士国家微电子研发中心__ [纳沙泰尔,瑞士] `2015.9 - 2016.4`
_算法研究员_<br>

* 非介入式血压机器学习方案,成功推动长期项目至最后阶段。（光生理信号模式识别和机器学习）
* Directed by Josep Solà I Càros

### __PSA,标志雪铁龙汽车全球研发总部__ [巴黎, 法国] `2015.3 - 2015.9`
_研发工程师_<br>

* 独立工作负责汽车人机交互项目的预研发（电生理信号模式识别）
* 建立一整套完整的从数字信号处理到模式识别的解决方案

<br>

## 领健工作内容细节 [ 2022.06 - now]

### __医患沟通用牙齿矫正模拟算法__
* 快速精确的牙齿矫正模拟功能,在<a href="#stablediffusion">stable diffusion</a>发布的最初阶段(2022年8月)即完成选型,定制化训练和本地工程化的工作.
* 针对diffusion族生成式网络进行深入研究,指导设计和架构适用于当前任务的新模型结构和约束，使得生成式模型有效性达到商用标准。

### __全颌可视化系统功能,算法侧架构__
* 基于锥形束CT数据(3D点云)的实例分割算法落地和研究优化.
* 多传感器数据高精度配准融合工作,数据源包括(CBCT,激光扫描,RGB图像,CT).通过掌握大量口腔解剖学知识,实现了超过业内最高水平的高精度的配准工作.
* 进展中发现了业内暂无人解决的基础性问题,协调组内的研究专家与业内专业教授联合研究。

### __算法在产品商业化上的应用实例__
* 配准用户多次不同时间段的牙齿三维扫描数据，分析形态进展与商业治疗计划的匹配性，解决商业化上的一个重要痛点（隐形矫正的重启率问题）
* 建立复杂的力学仿真方案，分析治疗过程中的颌骨和牙齿牙根结构之间的关系，用于产品的风险预警和管控。
* 基于大规模数据和硬性逻辑规则进行自动化的牙齿矫正算法架构设计，协调算法、医学、软件三个团队成功将新算法融合到现有成熟的商业化流程中，用于大幅提升人类设计师的工作效率，在服务于每天同样多的客服需求情况下，所需设计师总数量下降三倍。 

### __医疗影像识别任务综合平台__
* 架构一个全面的任务平台,用于多样的二维医疗影像数据的各类AI工作
* 实现多模态检索能力(使用文本搜索图像)
* 实现一般性的图片快速分类工作,落地成为内部服务,使得数据工程师可以从中快速自定义训练分类网络
* 设计和架构面向医疗影像的专业数据系统,包括医用的专业标注软件、数据检索系统，帮助在多个不同数据和任务上提供数据源
* 实现功能：Xray侧位片特征点定位，特殊组织分割，精确率达到行业内顶尖水平，对标行业内其他专业软件
* 实现功能：Xray全景片数据中，超过多达20种不同组织结构语义分割，超分辨率分割，细小目标结构定位，同类型组织的病理学阶段诊断，诊断可靠度（recall-94%），达到业内顶尖，超过很多已经商业化落地方案,与专业医生水平持平。
* 实现功能：支撑全部领健各类型数据的快速分类，部署，实现在毫秒级别的部署，支撑几千家用户的日常数据智能归档需求。

### __架构专业的医用计算机辅助诊断(CAD)平台__ 
* 与专业医学专家合作,消化行业内不同的需求列表.
* 综合需求列表,并根据需求解析成不同的算法工具链. 
* 特征点定位基础算法，用于在各类模态上进行关键的医用解剖学相关的特征点定位功能，用于为后续的诊断测量输出基础信息。
* RGB图像数据基础算法，包括人脸识别，口内照片的各类目标识别和实例分割
* Xray数据基础算法，包括侧位片，全景片，正位片的各类目标识别和实例分割
* 跨模态数据融合基础算法，能够有效融合上述三类数据，用于不同模态数据的协同分析工作，用于在不同的诊断场景下进行输出。

<div STYLE="page-break-after: always;"></div> 

## 翎腾工作内容细节 [ 2019.05 - 2022.05] 

### __机器人自主感知机械臂项目__ `2022 @翎腾`

* 机器人机械臂基于视觉反馈和力学反馈的自主抓握感知能力研究
  * 视觉数据的多模态理解,设计使用CLIP和ALBEF多模态框架完成视频流中的物体的检索
  * 检索来源于文字流,为未来直接接入语音控制做准备.打通语音,文字,图片,动作理解之间的跨模态通道
  * 使用mujoco框架来搭建其中的力学仿真环境,使用虚幻引擎搭建视觉仿真环境
  * 视觉(虚幻)和力学环境(mujoco)与通过同步通信,使得深度强化学习的agent可以同步在两个环境中获取反馈数据
  * 研究从虚拟环境到真实环境的迁移问题,并设计一套完整的迁移方案,使得agent可以在虚拟环境中学习到的知识可以在真实环境中得到应用

* 机器人3D视觉功能
  1. 熟悉和跟进机器人3D视觉研发前沿潮流（双目，单目，till 2022.05）
  2. 独立设计完善的基于虚幻引擎的机器人仿真视觉环境。并部署强化学习
  3. 完整架构和设计全新的视觉感知系统
  4. 设计全新架构基于transformer和CNN的神经网络结构,实现处理视频流理解和数据模态转换的神经网络
  5. 完成全部的数据链搭建，框架搭建，算法训练，算法量化，嵌入式终端部署工作，为机器人赋予视觉感知能力

### __基于计算机视觉的智能阅读学习设备__ `2019,2020,2021 @翎腾`

* 设计完整的计算机视觉和NLP算法框架,完成工作链中全部算法模型选型,架构设计,训练,轻量化,并部署到嵌入式设备中进行边缘运算
* 全场景OCR功能,支持超过20种印刷体文字,支持手写体英文和中文识别
* 手写体准确率水平对标腾讯优图，2020.10,印刷体准确率水平超过99%，对标业内绝大部分的OCR方案（百度，腾讯，科大讯飞,2021.03）
* 功能触发模块应用不同的触发物体识别,同时引入视频流理解算法架构,使得系统可以在保证对用户理解准确性的同时覆盖更多的任务场景,做到一种设备覆盖全部阅读场景.
* 主要的任务场景包括单词点读,交互式的多词或句子点读和翻译,手写过程跟踪,手写内容理解,多指手势等等.


### __个人核心研究方向__ `2019,2020,2021 @翎腾`

* zero-shot方案的CV任务, 如CLIP,Moco等对比学习或无监督学习方案.
* cross-domain gap,跟进数据增强,迁移学习,多任务学习,域自适应学习.
* 目标检测、全景分割、ReID等下游任务，具体网络包括DETR, SwinTransformer,MAE,yolo(v5,v3,yolox),centernet,Efficient-det,MaskRCNN等
* 基于时序的动态视频数据下的目标识别 
* 基于空间数据的3d数据的目标识别,ACVNet,PointNet++
* 多模态数据的理解和融合

### __算法在产品商业化上的应用实例__ `2019,2020,2021 @翎腾`

* 阅读学习场景的智能硬件（台灯，点读设备）
  1. 阅读辅助，单词点读识别功能
  2. 交互跟踪划线词句识别功能
  3. 书写过程笔迹跟踪和手写内容理解
  4. 双指交互自动摘抄功能
  5. 全线产品共三代硬件的迭代升级，总体出货量约10万+

* 教育辅助场景(教师用自动批改设备)
  1. 自动识别页面精确范围算法
  2. 自动识别页面信息算法（书本信息和页码）
  3. 针对常规练习册系统的自动判卷完整功能
  4. 针对常规练习册系统的精细化内容分离算法
  5. 支持了超过3万+教育系统使用者.日活用户超过1000+人.
  
### __深度学习数据系统__ `2019,2020,2021 @翎腾`

* 搭建完整的数据采集和实机测试系统
  1. 在嵌入式端使用模拟设备进行数据采集和离线数据管理
  2. 采集系统自动化采集、并进行记录和自动化上传
  3. 系统同时可以由采集人员完成实机设计场景测试

* 设计并指导开发数据标注系统
  1. 适配多功能的标注任务
  2. 完全自动化配置方案
  3. 全线上系统，可完全远程进行数据标注工作

* 设计并指导数据分发系统
  1. 标注数据自动化分发到具有相应权限的算法研发工程师，提高研发效率
  2. 自动更新标准测试数据库，有效跟进研发进度。

### __深度学习部署系统__ `2019,2020,2021 @翎腾`

* 服务端移植综合方案
  1. 设计并指导研发完整的线上部署方案(MLOps)
  2. 服务端方案有效实现完整的推理自动化，大幅提高算法工程师算法在服务端实现的效率
  3. 实现在算法工程师在PC平台只要拥有代码，就能到处移植运行。便于快速测试验证，并且拥有版本。
  4. 部署方案同时拥有算法指标验证功能，能够进行特定测试机制线上自动化运行。 

* 嵌入式端和设备端移植综合方案
  1. 针对不同的硬件设备提供商（Intel, Rockchip瑞芯微, google, 亿智）进行深度学习算法的移植工作
  2. 针对安卓系统或者IOS系统使用相应的算法框架（tflite, NCNN, MNN）进行深度学习的算法移植
  3. 常规使用的模型框架包括 tensorflow, pytorch, onnx, paddle-paddle.
  4. 完整支撑移植过程中的模型转化、参数量化、精确度保证等问题，成功进行超过30个不同的框架不同计算规模算法的嵌入式移植。


## 其他经验细节 [ 2015 - 2019.4]


### __人类运动生理相关人工智能识别检测系统__ `2020，2021 @第五区`

* 基于心率变异性的VAD情绪识别系统
* 基于多导检测系统的科学睡眠检测系统
* 基于心率和心率变异性的压力识别系统


### __人工智能运动生理指标识别检测系统__ `2018,2019 @第五区`

* 独立开发系统三部分核心算法
  1. 基于Photoplethygraph(PPG)技术的心率变异性水平计算算法，获得与传统ECG技术相同的准确度水平，并集成在嵌入式软件中。
  2. 基于LSTM的深度学习睡眠线上分析系统，有效甄别各类睡眠过程。 
  3. 基于嵌入式端的运动员日程运动量水平评估算法
* 与嵌入式软件团队配合进行嵌入式端算法部署实现。
* 与后端团队共同定义数据流和数据结构水平，并进行线上分析算法部署实现。


### __基于人工神经网络的音频识别__ `2018`
* 基于CNN的音频谱分析和RNN的音频目标识别
* 建立普适性框架用于算法部门内部其他机器学习任务使用。
* 负责整个项目的全部开发细节：
  1. 整理相关音频识别知识和经验，设计数据流
  2. 设计数据采集实验和标定工程 
  3. 编写GUI数据采集工具，并指导实验部门进行采集
  4. 数据预处理过程（数据事件自动标记，基础特征提取）
  5. 框架选择和本地配置
  6. 算法核心结构设计
  7. 制定评估准则并进行参数调整
  8. 执行线上模型部署

### __可穿戴设备完整算法的系统化设计和集成__ `2016,2017 @第五区`

* 长期作为主要算法工程师，进行可穿戴设备（手环形态）的各类算法的系统化设计。与嵌入式软件工程师紧密合作完成全部算法的集成工作
* 可穿戴设备内算法主要包括:
  * 基于多传感器合作下的多场景自动模式识别算法。
  * 运动场景数据信息化算法: 包括动态长效心率算法，高精度计步步频算法，运动强度水平监控，危险预警算法。
  * 心率变异性基本算法(基于PPG光电传感器)
  * 可穿戴设备形态的功能性算法，包括抬腕亮屏和佩戴脱落检测等。

### __基于非接触式心电的驾驶员疲劳异常预警系统研发设计__ `2015 @PSA`
* 独立设计建立实验系统用于采集相关电生理信号，同时进行多个传感器信号比对和选型。
* 对原始数据进行预处理并设计算法对疲劳异常相关的数据模式进行甄别。 

## 学术研究经历

### __EPFL, Hemodynamics and Cardiovascular Technology Laboratory(LHTC) Lab__ [洛桑，瑞士] `2014.9 - 2015.9`
_Research Assistant_<br>

* 对血管瘤CT成像结果进行3D建模并实现病理学计算视觉CNN模型。
* 负责血管瘤数据CT成像过程标注。
* 调查研究并将CNN模型引入到组内的研究过程中（组内之前一直使用传统图像处理方案）
* 模型识别准确率超过70%， train set 800. 
* Directed by Trachet Bram and Nikolaos Stergiopulos

### __EPFL, Defitech Chair in Brain-machine Interface(CNBI) Lab__ [洛桑, 瑞士] `2014.1 - 2014.9`
_Research Assistant_<br>
* 对脑机接口脑电EEG中可预见性事件异常模式通过RNN模型进行异常识别.
* Directed by Jose Del R.Millan

<br>


## 个人陈述

　　我从2013年开始从事深度学习相关研究工作,主攻计算机视觉和多模态深度学习方向。同时也拥有丰富的医疗影像学和数字信号处理相关工程产品经验。曾任职于标志雪铁龙(PSA)全球研发总部(法国巴黎), 瑞士国家微电子研发中心(CSEM)，回国后投入多个创业项目，一直致力于搭建最前沿的研究与产品工程化之间的桥梁。

　　我对人工智能领域的研究进展高度关注，拥有丰富的AI产品化经验，拥有独立研究以及带领团队研究和工程化落地的能力。任职多个创业公司的技术负责人和算法负责人，协作能力强大，学术研究视野广泛，产品思维全面，能够高效地与产品团队或者CEO协作，利用合适的前沿技术和出色的架构能力解决商业产品的问题。

　　我非常热衷于将最先进的研究成果应用于实际场景中，我个人的工作目标是将研究和产品实践相结合，帮助更多的人受益。因此，我希望能够加入一个创新型的公司或者研究团队，深入探索人工智能的领域，并将自己的专业知识和技能用于创造出更具有社会价值的产品。

## 语言

__中文:__ 母语　　|　　__英文:__ 专业熟练，工作常用语言（听说读写）　　|　　  __法文:__ 基础，仅日常阅读

<div STYLE="page-break-after: always;"></div> 
<br><br><br><br>
<h2></h2>


<div id="全景分割">
<h2>全景分割</h2>
🟢全景分割算法是一种计算机视觉技术，它可以将图像分成不同的区域，并为每个区域分配一个语义标签。全景分割算法在许多领域有广泛的应用，例如自动驾驶、医学影像分析、视频监控等。<br>
🟢在自动驾驶领域，全景分割算法是非常重要的。它可以帮助自动驾驶汽车实现道路标记识别、障碍物检测、车道检测等任务，从而实现对道路的理解和规划。此外，全景分割算法也被应用于无人机、机器人等领域。<br>
🟢另外，全景分割算法也在医学影像分析领域得到了广泛的应用。它可以帮助医生快速准确地分析病变区域，诊断疾病，并帮助制定治疗方案。<br>
🟢在视频监控领域，全景分割算法可以用于识别人、车、动物等物体，并对它们进行跟踪和识别，从而增强视频监控的效果。<br>
🟢综上所述，全景分割算法在许多领域都有广泛的应用，特别是在自动驾驶领域的应用最为广泛。<br>
</div>



<div id="Detectron2">
<h2>Detectron2</h2>
Detectron2是一个用于目标检测和分割的深度学习库，由Facebook AI Research开发，其目标是为计算机视觉研究者和开发者提供高效、灵活、易于使用的工具。Detectron2的主要功能包括支持多种常用的目标检测和分割算法，如Faster R-CNN、Mask R-CNN、RetinaNet等，并提供了许多优秀的特性，如分布式训练、GPU加速、模型微调等。
</div>

<div id="OpenMMLab">
<h2>OpenMMLab</h2>
OpenMMLab是一个面向计算机视觉的开源项目，旨在为研究者和工程师提供高效、灵活、易用的计算机视觉工具。OpenMMLab的功能非常丰富，包括了多个模块，如2D/3D检测、分割、姿态估计、人脸识别等。OpenMMLab使用PyTorch作为主要的深度学习框架，并提供了丰富的工具和API，如数据预处理、数据加载、模型定义、训练等，使得研究者和开发者能够更加高效地进行计算机视觉研究和应用开发。
</div>


<div id="stablediffusion">
<h2>stablediffusion</h2>
🟢Diffusion Model是由OpenAI提出的一种基于扩散过程的图像生成模型。该模型使用了一个逐步的过程，即从初始噪声图像开始，每个时间步骤都通过条件分布对当前图像进行扩散，从而生成一系列逐渐变得清晰的图像。Diffusion Model使用了可逆的动态生成过程，其中每个时间步骤都是可微分的，这使得该模型可以使用反向传播算法进行端到端的训练。<br>
🟢DDPM（Diffusion Probabilistic Models）是一种扩展的Diffusion Model。DDPM将每个时间步骤的条件分布建模为一个深度神经网络，使用对偶网络的方法进行训练，从而实现更高效的训练和更高质量的图像生成。此外，DDPM还使用了一种新的扩散过程，称为块扩散（block diffusion），可以在保持生成图像质量的同时减少生成时间和计算成本。<br>
</div>


<div id="zero-shot">
<h2>zero-shot</h2>
🟢Zero-shot 图像任务或小样本图像任务是指在只有少量或者没有标注数据的情况下，如何训练一个深度神经网络模型来完成图像分类、检测、分割等任务。这种任务常常是现实应用中的痛点之一，因为获取大量标注数据往往需要昂贵的人力、时间和成本。为解决这个问题，研究者们提出了一些方法和技术架构，下面简要介绍一些主要的方法：<br>
🔸迁移学习（Transfer Learning）：这种方法利用一个预训练的模型（如ImageNet）来提取图像的高级特征，然后在少量标注数据上进行微调，以适应新的任务。这种方法比较简单，但需要足够的预训练数据和与新任务相关的微调数据。<br>
🔸元学习（Meta Learning）：这种方法旨在训练一个模型，使其可以快速学习新任务。这种方法通常需要大量的小样本数据和合适的模型架构和优化算法。常见的元学习方法包括MAML、Reptile等。<br>
🔸生成模型（Generative Models）：这种方法使用生成模型来生成新的数据样本，以提高模型的泛化能力。生成模型可以利用已知类别的标注数据，来生成新的样本，从而扩充数据集。一些经典的生成模型包括VAE、GAN等。<br>
🔸模型集成（Model Ensembling）：这种方法使用多个模型，如模型融合、模型堆叠等，来增强模型的泛化性能。模型集成可以提高模型的稳定性和准确性，但需要更多的计算资源和模型设计和优化技巧。<br>
🟢总的来说，这些方法都可以在少量或没有标注数据的情况下完成图像任务，但需要考虑到任务的具体场景和数据特点，以选择合适的方法和技术架构。在实际应用中，还需要根据实际情况不断优化和调整模型，以达到最佳的性能和效果。<br>

🟢对于Zero-shot图像任务，CLIP提供了一种基于语言指导的零样本学习框架。CLIP使用文本描述作为图像类别标签，并利用其预训练模型学习到了图像和文本之间的对应关系，从而使得模型可以对未见过的图像进行分类。具体而言，给定一张未见过的图像，CLIP首先将其编码为一个特征向量，然后利用文本描述计算图像和文本之间的相似度，最终将其归为相似度最高的类别中。<br>
🟢这种基于语言指导的零样本学习框架可以广泛应用于各种应用场景中，如商业推荐、自然语言与图像的交互应用等。CLIP的出现为Zero-shot图像任务的研究提供了一种全新的思路和解决方案，大大拓展了零样本学习的应用领域。同时，CLIP的性能也取得了很好的成果，在许多经典的Zero-shot图像分类和检索任务上取得了state-of-the-art的效果。<br>
</div>




<div id="CLIP">
<h2>CLIP</h2>
🟢对比学习的跨模态预训练模型，其目的是让计算机能够更好地理解自然语言和图像之间的关系。CLIP采用Transformer网络结构，通过大规模的文本和图像数据进行无监督训练，学习到了一种通用的表示，可以用于多种下游任务，如图像分类、检索、生成等。<br>
🟢对于Zero-shot图像任务，CLIP提供了一种基于语言指导的零样本学习框架。CLIP使用文本描述作为图像类别标签，并利用其预训练模型学习到了图像和文本之间的对应关系，从而使得模型可以对未见过的图像进行分类。具体而言，给定一张未见过的图像，CLIP首先将其编码为一个特征向量，然后利用文本描述计算图像和文本之间的相似度，最终将其归为相似度最高的类别中。<br>
🟢这种基于语言指导的零样本学习框架可以广泛应用于各种应用场景中，如商业推荐、自然语言与图像的交互应用等。CLIP的出现为Zero-shot图像任务的研究提供了一种全新的思路和解决方案，大大拓展了零样本学习的应用领域。同时，CLIP的性能也取得了很好的成果，在许多经典的Zero-shot图像分类和检索任务上取得了state-of-the-art的效果。<br>
🔸...<br>
</div>


<div id="ALBEF">
<h2>ALBEF</h2>
🟢ALBEF（A Lite BERT for Adaptive Embedding of Images and Texts）是一种基于BERT的图像和文本的交互式嵌入算法，用于处理图像和文本数据的多模态融合。它由韩国电子通信研究院（ETRI）的研究人员于2020年提出。<br>
🟢ALBEF主要由两个组件组成：一个是基于Transformer的文本编码器，另一个是自适应图像编码器。这两个编码器都是基于BERT网络进行改进的。其中文本编码器主要用于将文本序列编码成一个固定长度的向量表示，而图像编码器则用于将图像转换为一个固定长度的向量表示。<br>
🟢对于文本编码器，ALBEF采用了BERT模型中的Transformer网络结构。输入文本序列先经过Embedding层转换成向量形式，然后通过多层Transformer编码器提取特征。与原始的BERT模型不同，ALBEF的Transformer编码器将使用动态卷积（Dynamic Convolution）替代标准的卷积操作，这样能够提高模型的计算效率。<br>
🟢对于图像编码器，ALBEF使用自适应的特征提取模块。具体而言，输入的图像先经过一个预处理网络，然后经过一个分级特征提取模块，该模块可以从不同的层次提取图像特征。特征提取后，ALBEF还使用了一种自适应池化方法，它可以根据输入的文本内容动态地调整特征的权重，从而使得模型更加注重与文本相关的特征。最后，经过一些全连接层的变换，图像也被转换为一个固定长度的向量表示<br>
🟢在训练时，ALBEF将最小化图像和文本之间的距离作为目标函数，同时还加入了负样本对比损失，以进一步增强模型的鲁棒性和泛化性能。<br>
🟢总的来说，ALBEF通过将文本和图像之间的交互信息嵌入到一个共同的向量空间中，能够实现图像和文本之间的语义关联，从而提高多模态数据的融合效果。它的优点在于能够有效地处理大规模数据，同时还能够实现高效的计算。<br>
</div>


<div id="DETR">
<h2>DETR</h2>
🟢DETR（DEtection TRansformer）是Facebook AI Research于2020年提出的目标检测算法，它将Transformer架构应用于目标检测领域，实现了端到端的目标检测，并在COCO数据集上取得了较好的性能。<br>
🟢DETR的主要架构由两个部分组成：编码器（Encoder）和解码器（Decoder）。编码器是一组卷积层，用于将输入图像转换为一组特征向量，这些特征向量可以被传递到解码器中。解码器包括一个Transformer编码器和一个特定于目标检测的解码器。<br>
🟢具体来说，解码器接受两个输入：编码器生成的特征向量和一组可变长度的对象查询（Object Queries）。对象查询是一组由Transformer编码器生成的特殊嵌入向量，用于表示检测框的类别和位置信息。解码器首先将这些对象查询与编码器生成的特征向量拼接在一起，然后将其输入到Transformer编码器中。Transformer编码器将生成一组新的特征向量，其中每个特征向量都对应于一个检测框，表示其在图像中的位置和类别信息。<br>
🟢然后，解码器使用一个全连接层对每个特征向量进行处理，从而得到检测框的位置和类别信息。最终，DETR使用一个损失函数来衡量模型的性能，其中包括分类损失和回归损失。<br>
🟢DETR的优点在于它不需要使用复杂的手工设计的模块，能够在不同的目标检测数据集上取得不错的性能，并且能够同时处理多个对象的检测。同时，由于采用了Transformer架构，DETR还可以利用全局信息来进行检测，从而在图像中存在大量目标的情况下取得更好的性能。<br>
</div>



<div id="BLIP">
<h2>BLIP</h2>
🟢BLIP是一个多模态混合编码器-解码器（MED）的模型架构，它由一个图像编码器（ViT），一个文本编码器（BERT），和一个文本解码器（GPT）组成1。<br>
🟢图像编码器用于提取图像特征，文本编码器用于提取文本特征，文本解码器用于生成文本。这三个模块可以根据不同的任务灵活地组合和激活12。<br>
🟢例如，对于图像-文本检索任务，可以激活图像编码器和文本编码器，并使用对比损失函数来对齐它们的特征空间；对于图像翻译任务，可以激活图像编码器和文本解码器，并使用交叉注意力机制来融合图像和文本信息12。<br>
🟢BLIP还使用了一种数据集自展（CapFilt）的方法，它可以从有噪声的图像文本对中筛选出高质量的数据进行预训练。CapFilt的核心思想是利用语言模型（LM）和视觉语言模型（VLM）来评估每个样本的质量，并根据一定的阈值来过滤掉低质量的样本2 。<br>
🔸CLIP 的数据来源于 Web 上爬来的 图像-文本对，所以数据集很容易扩充的很大，而且采用 对比学习 的方式，基本属于自监督了，不太需要做数据标注；<br>
🔸BLIP 改进了 CLIP 直接从 Web 取数据 噪声大 的缺点，提出了 Captioning and Filtering (CapFilt) 模块，这个模块就是用来 减小噪声、丰富数据 的，主要包括两个模块：<br>
🔸Captioner 字幕器：一个用于生成给定 web 图像字幕的字幕器，字幕器是一个基于图像的文本解码器，用 LM 目标函数激活，对给定图像的文本进行解码；<br>
🔸Filter 过滤器：一个用于去除噪声 image-text pair 的过滤器，过滤器是一个基于图像的文本编码器，用 ITC 和 ITM 目标函数激活，通过判断 原始文本 / 生成文本 和 图像是否匹配，用以过滤噪声文本，提高文本语料库的质量；<br>
🟢BLIP在多个视觉-语言理解和生成任务上都取得了SOTA结果，包括ImageNet-VQA、ImageNet-Captioning、MSCOCO-Retrieval、MSCOCO-Captioning等。<br>


🟢BLIP算法是一个新的视觉-语言预训练框架，可以支持比现有方法更广泛的下游任务123。根据我从网上搜索到的信息，BLIP算法可以用在以下几种下游任务：<br>

🔸图像描述（Image Captioning）：根据图像的内容生成一段描述性的文本13。<br>
🔸视觉问答（Visual Question Answering）：根据图像和用户提出的问题生成一个简短的答案13。<br>
🔸图像检索（Image Retrieval）：根据用户提供的文本或语音查询，从一个大规模的图像库中检索出最相关的图像23。<br>
🔸文本检索（Text Retrieval）：根据用户提供的图像或语音查询，从一个大规模的文本库中检索出最相关的文本23。<br>
</div>


<div id="BEiTV3">
<h2>BEiTV3</h2>
🟢BeiTV3算法是一种基于Transformer的多模态预训练模型，它可以同时处理图像和文本输入，并在不同的下游任务上进行微调。BeiTV3算法的核心思想是将图像视为一种外语，通过一个共享的词表和词嵌入层将图像和文本编码为相同的形式，然后通过多路Transformer进行交互和融合。BeiTV3算法具有高效、灵活、通用等优点，可以应对各种复杂的多模态场景。<br>

🟢BeiTV3算法的下游任务有很多，我可以列举一些例子。12<br>
🔸图像单模态任务：这些任务只涉及图像输入，比如图像分类（判断图像属于哪个类别），目标检测（找出图像中的物体并标注位置），分割（将图像分割成不同的区域）等。<br>
🔸文本单模态任务：这些任务只涉及文本输入，比如自然语言理解（理解文本的含义和逻辑），生成（根据文本生成新的文本）等。<br>
🔸图文任务：这些任务涉及同时处理图像和文本输入，比如视觉问答（回答关于图像的问题），视觉推理（判断两幅图像之间的关系）等。<br>
🔸图文检索：这种任务需要计算所有可能的图像和文本对之间的相似度，比如给定一个查询词，找出最相关的图像，或者给定一幅图像，找出最相关的描述。<br>
</div>

<div id="ITM">
<h2>ITM(image_text_maching) loss</h2>
🟢Image Text Matching Loss是一种用于图像和文本之间匹配的损失函数，通常用于训练图像和文本之间的相互对应关系。与ITC Loss类似，Image Text Matching Loss也是一种基于对比学习的损失函数，可以在图像和文本嵌入空间中学习到语义相关性。不同之处在于，Image Text Matching Loss将两个嵌入向量映射到同一维度，并通过余弦相似度来计算它们之间的距离。<br>

🟢具体来说，假设有一组图像$I={i_1, i_2, ..., i_n}$和一组文本$T={t_1, t_2, ..., t_n}$，每个图像和文本都有一个嵌入向量表示。Image Text Matching Loss的目标是通过最小化图像和文本之间的余弦距离，来学习图像和文本之间的相关性。对于每个图像$i$和对应的文本$t$，可以通过以下公式来计算它们的Image Text Matching Loss：<br>

🟢$L_{itm}(i, t) = -\log(\frac{\exp(s(i,t))}{\sum_{j=1}^{n} \exp(s(i, t_j))})$<br>

🟢其中，$s(i,t)$是图像$i$和文本$t$之间的余弦相似度，$\sum_{j=1}^{n} \exp(s(i, t_j))$是图像$i$和其他文本$t_j$之间的余弦相似度的和。因此，该损失函数的含义是：对于给定的图像和文本对$(i, t)$，它们之间的余弦相似度应该尽量大，而与其他媒介之间的余弦相似度应该尽量小。<br>

🟢通过使用Image Text Matching Loss进行训练，可以学习到一个图像和文本之间的嵌入向量空间，其中相似的媒介嵌入向量在嵌入空间中彼此靠近。这种方法可以应用于许多图像和文本之间的匹配任务，例如图像标注、视觉问答和图像文本匹配等。<br>
</div>



<div id="ITC">
<h2>ITC loss</h2>
🟢Image Text Contrastive（ITC） Loss是一种损失函数，它通常用于图像和文本之间的跨模态检索（cross-modal retrieval）任务。这个损失函数基于对比学习的思想，将图像和文本嵌入向量投射到相同的嵌入空间中，并通过最小化嵌入向量之间的欧几里得距离来学习两种媒介之间的语义关系。<br>

🟢具体来说，假设有一组图像$I={i_1, i_2, ..., i_n}$和一组文本$T={t_1, t_2, ..., t_n}$，每个图像和文本都有一个嵌入向量表示。ITC Loss的目标是让同一张图片和与之相关的文本之间的嵌入向量更加接近，而不同的图片和文本之间的嵌入向量距离则要尽量远离。因此，对于每个图像$i$和对应的文本$t$，可以通过以下公式来计算它们的ITC Loss：<br>

🟢$L_{itc}(i, t) = \sum_{j=1}^{n} \max(0, m + d(i, t) - d(i, t_j))$<br>

🟢其中，$m$是一个常数，用于指定不同的样本之间的距离阈值，$d(i,t)$是图像$i$和文本$t$之间的欧几里得距离，$d(i,t_j)$是图像$i$和其他文本$t_j$之间的欧几里得距离。因此，该损失函数的含义是：对于给定的图像和文本对$(i, t)$，它们与其他媒介$(i, t_j)$的距离应该大于一个固定的距离阈值$m$。<br>

🟢通过使用ITC Loss进行训练，可以学习到一个图像和文本之间的嵌入向量空间，其中相似的媒介嵌入向量在嵌入空间中彼此靠近。这种方法可以应用于许多图像和文本之间的跨模态检索任务，例如图像注释、视觉问答和图像文本检索等。<br>
</div>


<div id="血压">
<h2>可穿戴设备测血压</h2>
🟢最先进的血压可穿戴设备之一是Omron公司推出的HeartGuide血压手表。HeartGuide血压手表采用了传统的血压测量方法，即利用充气式袖带测量血压。它配备了一种特殊的柔性袖带，可在手表带上展开，然后通过向袖带充气来测量血压。这种测量方法比其他传感器技术更准确，但需要用户佩戴袖带并等待测量结果的时间较长。<br>
🟢HeartGuide血压手表不仅可以监测血压，还可以监测心率、步数、睡眠等生理参数。它配备了一个触摸屏，用户可以通过触摸屏来查看测量结果和其他信息。此外，HeartGuide血压手表还支持与智能手机配对，用户可以使用手机上的应用程序来跟踪和分析自己的健康数据。<br>
🟢HeartGuide血压手表是一种创新的血压可穿戴设备，它采用了传统的充气袖带测量方法，并配备了许多先进的功能，如触摸屏、配对应用程序等。它可以帮助用户更方便地监测自己的血压和其他生理参数，并及时发现健康问题。但需要注意的是，HeartGuide血压手表的价格较高，用户需要根据自己的需求和预算选择是否购买。<br>
</div>



<div id="血氧">
<h2>血氧</h2>
🟢目前市面上最先进的血氧可穿戴设备之一是Apple Watch Series 6。Apple Watch Series 6使用了一种称为脉搏氧饱和度（SpO2）传感器，它可以通过LED和光敏传感器检测血液中氧气的含量。<br>
🔸具体来说，Apple Watch Series 6在手腕上配备了一组红外LED和绿色LED，以及一个光敏传感器。当LED发出光线时，光敏传感器会测量光线的吸收量，然后计算出血液中氧气的含量。这个过程需要用户佩戴手表并保持手腕静止，通常只需要几秒钟即可完成。<br><br>
🟢Maxim Integrated是一家半导体公司，最近推出了一款名为Maxim MAX30102的可穿戴血氧传感器模块，可以与各种可穿戴设备配合使用。该模块使用了一种称为脉冲血氧测量（PPG）技术，可以通过LED和光敏传感器检测血液中氧气的含量。<br>
🔸具体来说，MAX30102模块使用红外LED和绿色LED照射皮肤，光敏传感器会检测反射回来的光线，并根据光线的吸收量计算出血液中氧气的含量。该模块还配备了一个专门的ASIC处理器，可以提供高质量的数据处理和降噪。<br>
🔸Maxim MAX30102模块可以与Arduino和Raspberry Pi等开发板配合使用，方便开发者快速搭建自己的可穿戴血氧监测设备。此外，该模块还具有低功耗、小尺寸、高精度和易于集成等优点，适用于多种应用场景。<br>
🔸需要注意的是，虽然Maxim MAX30102模块具有一定的精度和可靠性，但它仍然不是医疗设备，不能用于临床诊断或治疗。如果用户有任何健康问题，应咨询医生进行诊断和治疗。<br>
</div>




<div id="GLIP">
<h2></h2>
🟢GLIP算法是一种语言-图像关联预训练模型，它通过在大量的图像-文本对上进行短语关联任务，来学习对象级、语言感知和语义丰富的视觉表示1。GLIP算法与CLIP算法有一些相似之处，都是利用对比损失来训练多模态模型，但GLIP算法更注重图像中的细粒度对象和文本中的短语之间的对应关系23。<br>

🟢GLIP算法的优势或创新点主要有以下几个方面1：<br>
🔸它可以在大规模的无标注图像-文本对上进行预训练，从而学习到更多的视觉概念和语义信息。<br>
🔸它采用了深度跨模态融合的方式，而不是像CLIP算法那样仅在最后一层进行点积运算，这有助于提高语言感知视觉表示的质量和迁移学习性能。<br>
🔸它使用了短语关联任务作为预训练目标，这比CLIP算法使用的图像级分类任务更能捕捉图像中的细粒度对象和文本中的短语之间的对应关系。<br>
🟢GLIP算法在一些需要对象级视觉表示和语言感知能力的任务上表现出色，例如目标检测、分割、人体姿态估计、场景理解、动作识别、视觉语言理解等1。GLIP算法也可以在零样本设置下迁移到下游的图像分类和图文检索任务上，与CLIP算法类似23。
</div>


<div id="">
<h2></h2>
🟢...<br>
🔸...<br>
</div>



<div id="">
<h2></h2>
🟢...<br>
🔸...<br>
</div>




<h2></h2>
<h2>国民健康JD分析</h2>
<h2></h2>

* 工作职责：
  1. 负责与业务人员和领域专家进行深入沟通，梳理业务需求，并通过搭建基础数据平台和AI平台提供业务支持
  2. 负责AI团队的组建、管理和建设，指导团队成员不断成长并推进各项过程改进工作
  3. 负责大数据平台各类数据业务抽象及模型化，完成业务数据分析、加工、清理以及相关程序的开发，为业务系统和AI平台提供数据支持
  4. 负责机器学习和深度学习相关技术的探索和应用，根据领域数据提取特征并建立模型，提供离线&实时算法服务；负责智能健康产品重要场景算法的设计、研发和优化，包括但不限于计算机视觉算法、自然语言处理、个性化推荐系统等；
  5. 跟踪互联网领域内的用户画像、知识图谱等相关前沿技术和发展方向，并能够应用到实际业务领域中
* 任职要求： 
  1. 硕士及以上学历，计算机或数学相关专业，5年以上AI相关领域工作经历,2年以上团队管理经验，对数据平台建设、人工智能算法以及工程化应用有丰富经验
  2. 熟悉Python/Java语言，熟练掌握大数据技术体系，熟悉Hadoop/Spark/Hive/Hbase/Kafka/ES等主流工具和框架的工作原理与优化策略
  3. 对机器学习和深度学习的分类、回归、神经网络等常见算法的实现原理和应用场景有明确的认识；掌握scikit-learn、Tensorflow等常见算法开发框架和工具，对NLP、推荐系统、搜索等有实际应用和开发经验；
  4. 对特征工程有深入了解，能够根据业务需求抽象出算法模型，有健康医疗类行业背景优先考虑，有用户画像和知识图谱构建经验优先考虑。


* 工作职责：
  1. 负责与业务人员和领域专家进行深入沟通，梳理业务需求，并通过搭建大数据平台和AI平台提供业务支持
  2. 负责AI团队的组建、管理和建设，指导团队成员不断成长并推进各项过程改进工作
  3. 负责机器学习和深度学习相关技术的探索和应用，根据领域数据提取特征并建立模型，提供离线&实时算法服务；
  4. 负责智能健康产品重要场景算法的设计、研发和优化，包括但不限于计算机视觉算法、自然语言处理、个性化推荐系统等；
  5. 跟踪互联网医疗领域的用户画像、知识图谱等相关前沿技术和发展方向，并能够应用到实际业务领域中
任职要求： 
  1. 硕士及以上学历，计算机或数学相关专业，8年以上AI相关领域工作经历, 3年以上20人团队管理经验；
  2. 对模式识别、机器学习、深度学习、图像处理、神经网络等领域有深入认识，并了解各个算法的条件和瓶颈，对人工智能算法以及工程化应用有丰富经验；
  3. 熟悉C/C++和Python；精通图像相关算法，有OpenCV或者类似图形库开发经验；在人脸识别，活体检测，视觉图像检测等领域有规模化的算法落地实践 ；
  4. 熟悉Android平台、OpenCL/CUDA或者SIMD和TensorRT或者NCNN/Tengine，有客户端算法落地经验；
  5. 熟悉专利和论文发表流程；对NLP、推荐系统、大数据有一定了解；
  6. 有健康医疗类行业背景优先考虑，有用户画像和知识图谱构建经验优先考虑；
  7. 有高度的自驱力，追求极致；善于沟通和团队合作。



<div id="活体检测">
<h2>活体检测</h2>
🟢...<br>
🔸...<br>
</div>

是指通过人脸识别技术，判断识别者是否为真实的生物人而非照片、面具等非生物物品。下面是几种常用的活体检测技术方案：

眨眼检测：通过检测用户眼睛的自然眨眼行为，识别是否为真人。

嘴唇移动检测：通过检测用户嘴唇的自然移动行为，识别是否为真人。

头部转动检测：通过检测用户头部的自然转动行为，识别是否为真人。

3D结构检测：通过使用3D相机或深度相机采集的深度图像，检测人脸的深度信息，识别是否为真人。

红外光检测：通过检测人脸皮肤的红外光反射特征，识别是否为真人。

光线变化检测：通过检测用户周围环境的光线变化，识别是否为真人。

动作活体检测：通过要求用户在识别过程中进行特定动作（例如眨眼、张嘴、摇头等），并通过检测用户的动作完成情况，识别是否为真人。

综合使用多种技术方案，可以提高活体检测的准确性和鲁棒性


<div id="Tengine框架">
<h2>Tengine框架</h2>
🟢...<br>
🔸...<br>
</div>

Tengine 是由阿里巴巴开发的一款高性能、轻量级的 Web 服务器，同时也是一个支持动态模块化的 Web 应用服务器框架。Tengine 的核心是 Nginx，它在 Nginx 的基础上进行了深度定制和优化，主要针对大规模高并发的 Web 服务场景，具有高性能、高可靠性和可扩展性等特点。

除了作为 Web 服务器之外，Tengine 还提供了对 Lua 脚本的支持，可以通过编写 Lua 脚本实现动态功能扩展和业务逻辑处理。同时，Tengine 还支持通过动态模块的方式集成第三方扩展，如支持 FastCGI、HTTP 压缩、SSL、WebSocket 等。

除了 Tengine Web 服务器，阿里巴巴还开发了 Tengine 深度学习框架。Tengine 深度学习框架是一个针对嵌入式设备和边缘计算场景的深度学习推理引擎，具有轻量级、高性能、易移植等特点。它可以支持多种硬件平台和操作系统，并提供了丰富的深度学习算法库和优化方法，可用于实现各种深度学习应用。



<div id="TensorRT">
<h2>TensorRT</h2>
🟢...<br>
🔸...<br>
</div>
TensorRT（Tensor Runtime）是由 NVIDIA 开发的深度学习推理加速库，用于在 NVIDIA GPU 上优化和加速深度学习模型的推理过程。TensorRT 可以通过深度学习框架的转换工具将训练好的深度学习模型转换为 TensorRT 的优化模型，从而在推理阶段获得更高的性能和更低的延迟。

TensorRT 基于 CUDA 和 cuDNN 库实现，支持 NVIDIA 的各种 GPU 架构，并提供了一系列的高效算法和优化技术，包括精度损失量化、层融合、张量内存优化等，可以大幅提高深度学习模型的推理速度和效率。TensorRT 还提供了 C++ 和 Python 接口，可以方便地集成到深度学习应用程序中。

TensorRT 主要适用于需要在实时性要求较高的场景下进行深度学习推理的应用，例如自动驾驶、视频分析、语音识别等。

<div id="自然语言处理">
<h2>自然语言处理</h2>
🟢...<br>
🔸...<br>
</div>


是的，自然语言处理中有一些轻量化部署的算法方案。以下是一些常用的轻量化自然语言处理算法：

BERT Tiny

BERT Tiny 是 Google 在 2019 年发布的一个轻量化版本的 BERT 模型，它具有与原始 BERT 模型相似的性能，但参数数量仅为原始模型的 4% 左右。BERT Tiny 可以被用于诸如文本分类、情感分析等任务中。

DistilBERT

DistilBERT 是 Hugging Face 在 2019 年发布的一个轻量化版本的 BERT 模型，它的参数数量只有原始模型的一半左右，同时保留了大部分性能。DistilBERT 可以被用于诸如文本分类、情感分析、命名实体识别等任务中。

MobileBERT

MobileBERT 是 Google 在 2020 年发布的一个轻量化版本的 BERT 模型，它的参数数量仅为原始模型的 4.3%，同时保留了大部分性能。MobileBERT 可以被用于诸如文本分类、情感分析、问答系统等任务中。

ALBERT Lite

ALBERT Lite 是 Hugging Face 在 2020 年发布的一个轻量化版本的 ALBERT 模型，它的参数数量仅为原始模型的 18%，同时保留了大部分性能。ALBERT Lite 可以被用于诸如文本分类、情感分析、命名实体识别等任务中。

除此之外，还有一些针对特定任务的轻量化算法，例如 FastText 和 TextCNN 等算法，它们可以被用于诸如文本分类、情感分析等任务中。这些轻量化算法可以使用 TensorFlow Lite、ONNX Runtime、OpenVINO 等深度学习部署框架进行部署，以实现在移动设备、边缘设备等资源有限的场景中的高效部署。



<div id="推荐系统">
<h2>推荐系统</h2>
🟢...<br>
🔸...<br>
</div>

现阶段的大规模商用推荐系统一般会包含以下几个主要模块：

数据层

推荐系统需要海量的数据支撑，包括用户历史行为数据、商品信息、用户画像等。这些数据需要被高效地存储和管理，通常使用分布式存储和计算系统（如 Hadoop、Spark 等）来存储和处理数据。

特征工程

推荐系统需要从用户行为数据和商品信息中提取特征，这些特征可以用于训练模型和预测用户行为。特征工程包括特征提取、特征变换、特征选择等。常用的特征包括用户基本信息、历史行为、社交网络信息等。

模型层

推荐系统使用机器学习和深度学习模型来预测用户行为和商品推荐。目前比较常用的推荐算法包括基于协同过滤的算法、基于矩阵分解的算法、基于深度学习的算法等。推荐系统通常需要针对不同的场景和数据进行模型调优和优化。

实时计算

推荐系统需要实时计算和处理用户的行为，生成实时推荐结果。实时计算通常使用流计算系统（如 Flink、Storm 等）来实现。

推荐服务

推荐系统需要将实时推荐结果通过 API 接口暴露给客户端，可以使用 Web 服务器、微服务等方式实现推荐服务。

除此之外，推荐系统还需要考虑数据安全、隐私保护、AB测试等问题。现阶段的大规模商用推荐系统通常需要支持海量的用户和商品，同时还需要支持多种推荐策略，以满足不同用户的需求。



<div id="推荐系统算法">
<h2>推荐系统算法</h2>
🟢...<br>
🔸...<br>
</div>
推荐系统使用的算法种类比较多，常见的包括：

基于协同过滤的算法：这种算法根据用户历史行为和兴趣，寻找和当前用户兴趣相似的其他用户或商品，然后利用这些相似用户或商品的行为进行推荐。常见的协同过滤算法包括基于用户的协同过滤和基于物品的协同过滤。

基于内容的推荐算法：这种算法根据用户历史行为和兴趣，以及商品本身的特征，对商品进行推荐。常见的基于内容的推荐算法包括 TF-IDF 算法和基于文本相似度的算法。

矩阵分解算法：这种算法将用户历史行为和商品信息表示成一个低维向量，然后通过向量乘积来预测用户对商品的评分或兴趣。常见的矩阵分解算法包括基于奇异值分解（SVD）的算法和基于因子分解机（FM）的算法。

深度学习算法：这种算法利用神经网络等深度学习模型对用户和商品进行表示学习，然后利用学习到的表示进行推荐。常见的深度学习算法包括基于卷积神经网络（CNN）的算法和基于循环神经网络（RNN）的算法。

强化学习算法：这种算法通过交互式学习的方式，根据用户的反馈来更新推荐策略。常见的强化学习算法包括 Q-Learning 算法和 Actor-Critic 算法。

不同的算法适用于不同的场景和数据，推荐系统通常需要根据实际情况选择合适的算法。同时，不同的算法也有各自的优缺点，需要根据实际情况进行权衡和选择。


<div id="深度学习推荐算法应用">
<h2>深度学习推荐算法应用</h2>
🟢...<br>
🔸...<br>
</div>
深度学习推荐算法在推荐系统中应用广泛，以下是一些常见的应用：

电商推荐

在电商平台上，深度学习推荐算法可以根据用户的历史浏览记录、购买记录等信息，为用户推荐符合其个性化需求的商品。

视频推荐

在视频推荐系统中，深度学习推荐算法可以根据用户的观看历史、观看行为等信息，为用户推荐感兴趣的视频。

社交推荐

在社交网络中，深度学习推荐算法可以根据用户的社交行为、兴趣爱好等信息，为用户推荐感兴趣的内容和社交关系。

音乐推荐

在音乐推荐系统中，深度学习推荐算法可以根据用户的听歌历史、点赞行为等信息，为用户推荐符合其个性化需求的音乐。

文本推荐

在文本推荐系统中，深度学习推荐算法可以根据用户的搜索历史、文本内容等信息，为用户推荐符合其个性化需求的文章、新闻等。

总之，深度学习推荐算法已经成为推荐系统中不可或缺的一部分，在各种应用场景中发挥着越来越重要的作用。



当涉及深度学习推荐算法时，以下是几个常见的应用实例：

基于矩阵分解的推荐算法

矩阵分解算法是一种常见的深度学习推荐算法，可以将用户-物品评分矩阵分解成两个低维度的矩阵，从而捕捉用户和物品的潜在特征。在实现时，可以使用基于梯度下降的方法来最小化预测评分和实际评分之间的均方误差（MSE），以更新用户和物品的潜在特征。

基于深度神经网络的推荐算法

深度神经网络（DNN）在推荐系统中的应用也越来越广泛。例如，可以使用基于DNN的召回模型来预测用户是否会对某个物品感兴趣，并根据其预测的兴趣度对物品进行排序。此外，也可以使用基于DNN的排序模型来直接预测用户-物品的评分。

基于序列模型的推荐算法

在序列推荐中，考虑用户在一段时间内对物品的行为序列。基于序列模型的推荐算法可以通过对用户历史行为序列的建模，来预测用户的下一步行为并为其推荐物品。例如，可以使用循环神经网络（RNN）或其变体，如长短期记忆网络（LSTM）和门控循环单元（GRU），来捕捉用户行为序列的时间依赖性并进行预测。

以上是几个常见的深度学习推荐算法及其应用实例。需要指出的是，实际应用中的推荐算法通常会结合多种技术，以提高推荐准确度和覆盖率。


<div id="知识图谱">
<h2>知识图谱</h2>
🟢...<br>
🔸...<br>
</div>
知识图谱是一种用于表示和存储人类知识的结构化知识库，通常以图形结构的形式展现实体、概念和它们之间的关系。知识图谱是一种新兴的人工智能技术，具有广泛的应用前景，包括搜索引擎、问答系统、智能客服、推荐系统、自动驾驶等。

知识图谱的本质是将人类知识进行结构化、量化、可视化、存储和检索，是一种计算机可理解的人类知识表示形式。知识图谱的建设需要依靠大规模的数据收集、自然语言处理、知识抽取和图谱建模等技术。其中，自然语言处理和知识抽取是构建知识图谱的核心技术，通过对海量文本数据进行实体识别和关系抽取，从而将分散在各个数据源中的知识整合到一个统一的知识库中。

知识图谱的最大特点是将知识进行结构化，可以方便地进行查询、推理和应用开发。相比传统的关系型数据库和搜索引擎，知识图谱更加注重语义表示和关系建模，能够更好地处理复杂的知识关系和推理问题。此外，知识图谱还具有自我学习和自我更新的能力，能够根据新的数据和知识不断更新和优化自己。

知识图谱的发展和应用正在不断拓展，未来将成为人工智能和大数据领域的重要技术和基础设施之一。




<div id="知识图谱的构建">
<h2>知识图谱的构建</h2>
🟢...<br>
🔸...<br>
</div>
知识图谱的构建通常包括以下几个步骤：

数据收集：从各种数据源（如文本、数据库、网页、社交媒体等）中收集相关数据，并将其转换为机器可读的格式。

实体识别和关系抽取：使用自然语言处理（NLP）技术和机器学习算法，对文本数据进行实体识别和关系抽取，即从文本中提取实体和实体之间的关系。

知识表示：将实体和关系表示为计算机可理解的形式，如图形结构或者向量空间中的坐标。

知识存储：将知识图谱存储在图形数据库或者其他专门的知识库中，以便于快速访问和查询。

知识推理：对知识图谱进行推理和推断，从而得出新的知识和关系，以及修正现有的知识和关系。

应用开发：基于构建好的知识图谱，开发具体的应用，如问答系统、智能客服、推荐系统等。

以上步骤并不是严格的线性顺序，有些步骤可能需要反复迭代，也可以同时进行。此外，知识图谱的构建需要结合具体的应用场景和领域知识进行设计和优化。



<div id="GPT-3微调">
<h2>GPT-3微调</h2>
🟢...<br>
🔸...<br>
</div>

- Elicit是一个可以帮助用户创建高效问卷的应用。它使用了微调后的GPT-3来生成更易懂、更准确、更多样化的问题和选项。在用上定制版GPT-3后，Elicit给出的结果在易懂性上提高了24%、准确性上提高了17%、整体方面则提升了33%¹。
- Viable是一个可以智能读取用户评论的应用。它能够从大量评论中读取用户的重要建议，比如投诉、疑问等。定制化GPT-3使该应用在识别用户反馈的准确率上从66%提升到了90%¹。
- OpenAI团队自己也使用了微调后的GPT-3来完成各种自然语言任务，包括翻译、问答和内容摘要等。他们发现，微调后的GPT-3在许多NLP数据集上均有出色的性能，无需进行任何额外的梯度更新或微调²。
- 陈丹琦团队提出了一种基于语言模型的小样本微调方法（LM-BFF），该方法借鉴了GPT-3思想（引入提示和样本示例），并在低资源设置下，比普通的标准微调方法最高提升30%、平均提升11%³。

这些都是一些使用GPT-3微调模型取得良好效果的案例，你可以参考一下。😊

源: 与必应的对话， 2023/2/24(1) OpenAI开放GPT-3微调功能，一行命令就能实现！正确率最高提升4倍 - 知乎. https://zhuanlan.zhihu.com/p/445606136 访问时间 2023/2/24.
(2) 1750亿参数，史上最大AI模型GPT-3上线：不仅会写文章、答题，还懂数学 - 知乎. https://zhuanlan.zhihu.com/p/144764546 访问时间 2023/2/24.
(3) GPT-3的最强落地方式？陈丹琦提出小样本微调框架LM-BFF，比普通微调提升11%～ - 知乎. https://zhuanlan.zhihu.com/p/341609647 访问时间 2023/2/24.



目前，OpenAI已经开放了GPT-3的微调功能，用户可以通过OpenAI CLI来创建和使用微调后的模型1。这需要用户有OpenAI的API访问权限，并且微调后模型每1K token的费用，将比基础版高出50%1。

另外，也有一些开源项目试图复现GPT-3的预训练模型，例如Eleuther AI推出的GPT-Neo234。这个项目在GitHub上公开了两个参数规模分别为1.3B和2.7B的模型，并提供了Colab notebook来完成微调。虽然这些模型与真正的GPT-3相比，参数量仍然很小，但是它们是免费且开源的，可以供用户自由使用和修改。

你可以根据你的需求和资源选择合适的方案来使用GPT-3微调模型。😊


<div id="LM-BFF">
<h2>GPT-3微调 LM-BFF</h2>
🟢...<br>
🔸...<br>
</div>
LM-BFF是一套针对小样本进行微调的简单技术，主要包括两部分：基于提示（prompt）进行微调，关键是如何自动化生成提示模板；将样本示例以上下文的形式添加到每个输入中，关键是如何对示例进行采样12。LM-BFF的目标是让预训练的语言模型在少量标注数据上表现更好3。

LM-BFF是受GPT-3启发的一种小样本微调方法，它将下游任务视为一种掩码语言建模（MLM）问题，并使用提示模板（template）和标签词（verbalizer）来构造输入12。
LM-BFF使用T5模型来自动创建提示模板，通过交叉验证方法获得最优的模板和标签词2。这样可以避免人工标注的偏差和局部最优问题2。
LM-BFF还动态地选择样本示例，作为输入的上下文，以增强预训练模型对任务的理解12。它使用一种基于相似度和多样性的采样策略，从训练集中选择与当前输入最相关但不重复的示例1。

LM-BFF在以下几种NLP任务上表现得比较好：

文本分类（text classification），例如情感分析（sentiment analysis）、自然语言推理（natural language inference）等12。LM-BFF在这些任务上相比于标准微调方法，平均提升了11%，在SNLI数据集上提升了30%1。
命名实体识别（named entity recognition），例如从文本中识别人名、地名、组织名等1。LM-BFF在这个任务上相比于标准微调方法，提升了6.5%1。
关系抽取（relation extraction），例如从文本中抽取实体之间的关系，如婚姻、工作等1。LM-BFF在这个任务上相比于标准微调方法，提升了4.8%1。


- LM-BFF的官方代码和数据集，以及论文《Making Pre-trained Language Models Better Few-shot Learners》的链接，都在GitHub上¹。
- LM-BFF的简介和实验结果，以及论文《Making Pre-trained Language Models Better Few-shot Learners》的下载链接，都在知乎上²。
- LM-BFF的详细解读和总结，以及相关文献和博客的链接，都在CSDN上³。

源: 与必应的对话， 2023/2/24(1) GitHub - princeton-nlp/LM-BFF: ACL'2021: LM-BFF: Better Few-shot Fine .... https://github.com/princeton-nlp/LM-BFF 访问时间 2023/2/24.
(2) GPT-3的最强落地方式？陈丹琦提出小样本微调框架LM-BFF，比普通微调提升11%～ - 知乎. https://zhuanlan.zhihu.com/p/341609647 访问时间 2023/2/24.
(3) 论文解读：Making Pre-trained Language Models Better Few-shot Learners（LM-BFF .... https://blog.csdn.net/qq_36426650/article/details/115640052 访问时间 2023/2/24.

<div id="用户画像">
<h2>用户画像</h2>
🟢...<br>
🔸...<br>
</div>

用户画像，即用户信息标签化，是一种通过收集和分析用户的社会属性、生活习惯、消费行为等数据，来抽象出一个用户的特征和需求的方法123。用户画像可以帮助企业或产品更好地了解目标用户，提供定向广告投放和个性化推荐等服务14。

构建用户画像的主要步骤有以下几个¹³⁵：

- 收集用户的真实信息，包括人口统计学特征、网络行为、消费习惯等。
- 给用户贴标签，表示用户的不同维度特征，如性别、年龄、地域、兴趣爱好、消费能力等。
- 分析用户的目标和动机，了解用户使用产品的场景和需求。
- 抽象出典型的用户群体或类型，给每种类型赋予名称、照片、描述等，形成一个人物原型。

源: 与必应的对话， 2023/2/24(1) 一文读懂什么是用户画像，如何建立正确的用户画像 - 知乎. https://zhuanlan.zhihu.com/p/356948892 访问时间 2023/2/24.
(2) 什么是用户画像？如何构建用户画像？ - 知乎. https://www.zhihu.com/question/372802348 访问时间 2023/2/24.
(3) 如何建立用户画像（详细步骤） - 知乎. https://zhuanlan.zhihu.com/p/27174862 访问时间 2023/2/24.
(4) 一文读懂什么是用户画像，如何建立正确的用户画像 - 知乎. https://zhuanlan.zhihu.com/p/356948892 访问时间 2023/2/24.
(5) 利用Python搭建用户画像系统_桓桓桓桓的博客-CSDN博客. https://blog.csdn.net/u013043346/article/details/77712408 访问时间 2023/2/24.
(6) 构建用户画像的流程与方法 - 知乎. https://zhuanlan.zhihu.com/p/335062591 访问时间 2023/2/24.


构建用户画像需要用到大量的用户数据，因此需要选择合适的数据库或者后端方案来存储和处理数据。不同的数据库或者后端方案有各自的优劣，需要根据具体的业务场景和需求来选择。

一般来说，构建用户画像可以分为两种方式²：

- 单个用户画像：针对某一个特定的用户，通过分析其个人信息、行为数据、关系链等，给其打上标签，形成一个完整的用户信息全貌。
- 批量用户画像：针对一群相似的用户，通过聚类分析、统计分析等，给每个用户打上标签，形成一个多维度的用户信息矩阵。

不同的方式可能需要不同的数据库或者后端方案。例如：

- 单个用户画像可能需要用到关系型数据库（如MySQL）或者文档型数据库（如MongoDB），来存储和查询用户的基本信息、行为数据、关系链等。
- 批量用户画像可能需要用到大数据平台（如Hadoop）或者云计算服务（如AWS），来进行海量数据的采集、清洗、分析等。

源: 与必应的对话， 2023/2/24(1) 06.如何构建用户画像系统？看这一篇就够了！ - 知乎. https://zhuanlan.zhihu.com/p/346701627 访问时间 2023/2/24.
(2) 干货 | 数据分析之用户画像方法与实践 - 知乎. https://zhuanlan.zhihu.com/p/54843812 访问时间 2023/2/24.
(3) 构建用户画像的流程与方法 - 知乎. https://zhuanlan.zhihu.com/p/335062591 访问时间 2023/2/24.


用户画像有不同的类型，根据创建方式和数据来源的不同，可以分为以下三种¹：

- 初级用户画像：这种用户画像是基于团队或者利益相关者对用户的假设和经验，而不是基于真实的研究数据。它可以帮助快速调整产品方向和目标用户，但也可能存在偏差和误导。
- 定性用户画像：这种用户画像是基于小样本的定性研究，例如访谈、可用性测试或现场调研等。它可以帮助深入了解用户的需求、痛点、行为等，但也可能存在局限性和难以推广。
- 统计用户画像：这种用户画像是基于大样本的定量研究，例如问卷调查、数据分析等。它可以帮助发现用户的规律、特征、偏好等，但也可能存在复杂性和难以解释。

源: 与必应的对话， 2023/2/24(1) 用户画像的三种类型：初级、定性、统计 | 人人都是产品经理. https://bing.com/search?q=%e7%94%a8%e6%88%b7%e7%94%bb%e5%83%8f%e7%b1%bb%e5%9e%8b 访问时间 2023/2/24.
(2) 用户画像最全解析,超详细! - 知乎. https://zhuanlan.zhihu.com/p/382137186 访问时间 2023/2/24.
(3) 手把手教你做用户画像：3种标签类型、8大系统模块 - 知乎. https://zhuanlan.zhihu.com/p/125741500 访问时间 2023/2/24.
(4) 用户画像的三种类型：初级、定性、统计 | 人人都是产品经理. https://www.woshipm.com/user-research/4081372.html 访问时间 2023/2/24.



<div id="用户画像用于智能推荐">
<h2>用户画像用于智能推荐</h2>
🟢...<br>
🔸...<br>
</div>
用户画像在智能推荐领域的应用场景主要是利用用户的标签和偏好来给用户推荐感兴趣的信息或产品1。智能推荐算法有多种，例如基于流行度、基于协同过滤、基于内容、基于知识等。



- 基于流行度的推荐算法是最简单的一种，它只考虑物品的流行程度，不考虑用户的个性化需求。它的优点是实现简单，适用于新用户和冷启动问题；缺点是缺乏个性化和多样性，容易导致热门物品过度推荐。
- 基于协同过滤的推荐算法是利用用户对物品的评分或行为来预测用户对其他物品的喜好程度。它分为基于用户和基于物品两种类型。基于用户的协同过滤是给用户推荐和他兴趣相似的其他用户喜欢的物品；基于物品的协同过滤是给用户推荐和他已经喜欢的物品相似的其他物品。它们的优点是能够提供个性化和多样化的推荐；缺点是需要大量的用户评分数据，计算复杂度高，难以处理稀疏性、新颖性和可扩展性问题。
- 基于内容的推荐算法是利用物品或用户本身具有的特征来进行推荐。它分为基于物品内容和基于用户内容两种类型。基于物品内容的推荐算法是给用户推荐与他已经喜欢或浏览过的物品具有相似特征（如类别、标签、主题等） 的其他物品；基于用户内容 的推荐算法是给用户推荐与他的个人特征（如年龄、性别、地域等）相匹配的物品。它们的优点是不需要用户评分数据，可以解决冷启动和新颖性问题，并可以提供解释性的推荐;缺点是需要对物品和用户进行特征提取和表示，难以捕捉用户和物品的复杂和动态的兴趣。
- 基于知识（或规则）的推荐算法是利用领域知识或规则来进行推荐。它分为基于知识库和基于实例（或案例）两种类型。基于知识库（或本体）的推荐算法是给用户推荐符合其明确或隐性需求（如功能、价格等）的物品，并根据用户和物品在知识库中的关系来提供解释性的推荐;基于实例（或案例）的推荐算法是给用户推荐在过去类似情况下被证明有效或成功解决问题（如购买决

源:与必应的对话，2023/2/24(1)推荐算法分类：协同过滤推荐、基于内容推荐、基于知识推荐、混合推荐 - 知乎. https://zhuanlan.zhihu.com/p/351493402 访问时间 2023/2/24.
(2) 基于协同过滤的推荐算法综述 - 知乎. https://zhuanlan.zhihu.com/p/338582478 访问时间 2023/2/24.
(3) 【学习笔记02】推荐系统——经典算法（基于内容、协同过滤、混合等） - 知乎. https://zhuanlan.zhihu.com/p/108759393 访问时间 2023/2/24.